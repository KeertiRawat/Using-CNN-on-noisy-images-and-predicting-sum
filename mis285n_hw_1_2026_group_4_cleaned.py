# -*- coding: utf-8 -*-
"""MIS285N_HW_1_2026_Group_4_cleaned.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VsMAVq8laeQXBWaIp203BDCMNj2IiDhG

# MNIST CAPTCHA

### **Team Members (Group 4):** Christian Breton, Stiles Clements, Keerti Rawat and Carolina Rios.

In this notebook you will solve a simple CAPTCHA problem involving addition problems that use MNIST digits.

## Import some Libraries
"""

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from gdown import download
from PIL import Image
import matplotlib.pyplot as plt

"""## Download the data

## Captcha data

Captchas are 28×140 images split into five 28×28 chunks: digit, digit, operator, digit, digit. Labels are numeric results.
"""

# Download provided captcha datasets (public have labels; private do not)
download(id='18IZn5DroVvTkGJEKn5w15RuT61ET9HP0', output='public-clean.png', quiet=False)
download(id='1y3xX9VrM7EtYf1W-3vr-PETE19FnTKHR', output='public-clean.txt', quiet=False)

download(id='1cvDlXQrkLvR_tQBydyms-dt-VSjB7RlG', output='public-noisy.png', quiet=False)
download(id='1V-e76Q8Op3FWFEqb42bvJKllM5LfCdVS', output='public-noisy.txt', quiet=False)

download(id='1JfbYOpBHNrlz-fqgOtLZ8QDidxznug7U', output='private-clean.png', quiet=False)
download(id='1WtozDPV0FjmPthKBBiqBPfd-lhCMxfzk', output='private-noisy.png', quiet=False)

# Utility to load captcha images and (if present) their labels
import os
def showImage(tensor):
    transform = transforms.ToPILImage()
    return transform(1-tensor)
def readExamples(file_name):
    transform = transforms.ToTensor()
    image = Image.open(file_name + '.png').convert('L')
    tensor = 1-transform(image)
    X = tensor.reshape(-1,1,28,140)
    if os.path.exists(file_name + '.txt'):
        with open(file_name + '.txt') as f:
            lines = f.readlines()
    else:
        lines = ['']*X.shape[0]
    return X, lines

"""## Visualize some of the data

We have easy (clean) CAPTCHA problems, and noisy problems.

Let's have a look at some of these.
"""

# visualize
examples, labels = readExamples('private-clean') # or 'public-noisy' or 'private-clean' or 'private-noisy'
print(labels[0])
showImage(examples[0])

len(labels)

examples, labels = readExamples('private-noisy') # or 'public-noisy' or 'private-clean' or 'private-noisy'
print(labels[0])
showImage(examples[0])

len(labels)

"""# Your Task

You must find a way to solve the problems in ``private-clean`` and ``private-noisy`` for which we have not provided answers.

As you can see from the ``len(labels)`` commands, there are 2500 clean and 2500 noisy captchas you must solve.

Submit a txt file in the same format as the examples we have provided for the public data sets.

In addition to that txt file which will be used to compute a grade, please also submit your jupyter notebook containing the code that produced your solution (including any neural networks you trained, etc.)

## Problem 1 (Warmup)

A. Download MNIST. Create a train/test split if the downloaded data are not already in this format.

B. Create dataloaders and anything else you need.

C. Write a training function, or adapt one from last semester.

D. Build a simple **linear** neural network (i.e., logistic regression) in Pytorch, and train it on MNIST.

E. What is the testing accuracy that you find?

### Tasks A - B
Download MNIST. Create a train/test split if the downloaded data are not already in this format.

Create dataloaders and anything else you need.
"""

# Transform to convert images to tensors
transform = transforms.Compose([transforms.ToTensor()])

# Download and load the training data
train_dataset = torchvision.datasets.MNIST(
    root='./data',      # Directory to store the data
    train=True,         # Specify training data
    download=True,
    transform=transform # Apply the transform
)

# Download and load the test data
test_dataset = torchvision.datasets.MNIST(
    root='./data',
    train=False,        # Specify test data
    download=True,
    transform=transform
)

# DataLoader to iterate over the dataset
from torch.utils.data import DataLoader
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

print(len(train_dataset))
print(len(test_dataset))

# Get one batch from the DataLoader
images, labels = next(iter(train_loader))

print("Images shape:", images.shape)
print("Labels shape:", labels.shape)

print("Image dtype:", images.dtype)
print("Label dtype:", labels.dtype)

print("Label min/max:", labels.min().item(), labels.max().item())

"""### Task C
Write a training function
"""

# Generic training loop used for MNIST models
def train_one_epoch(model, loader, optimizer, criterion, device):
    """
    Trains the model for exactly 1 epoch.
    Returns (avg_loss, accuracy).
    """
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for images, labels in loader:
        images = images.to(device)
        labels = labels.to(device)

        logits = model(images)                 # shape: (B, 10)
        loss = criterion(logits, labels)

        optimizer.zero_grad() # clear gradients
        loss.backward()       # backward pass
        optimizer.step()      # update weights

        # accumulate metrics
        batch_size = labels.size(0)
        total_loss += loss.item() * batch_size
        preds = logits.argmax(dim=1)           # predicted class id
        correct += (preds == labels).sum().item()
        total += batch_size

    avg_loss = total_loss / total
    acc = correct / total
    return avg_loss, acc

"""### Task D
Build a simple linear neural network (i.e., logistic regression) in Pytorch, and train it on MNIST

#### Logistic regression baseline

Train a linear classifier on MNIST and report test accuracy.
"""

class LogisticMNIST(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(28 * 28, 10)  # 784 -> 10 classes

    def forward(self, x):
        x = x.view(x.size(0), -1)         # flatten: (B, 1, 28, 28) -> (B, 784)
        return self.fc(x)                 # logits (no softmax)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = LogisticMNIST().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)  # simple baseline

# DataLoader to iterate over the TEST dataset
test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)

# Evaluate testing accuracy
@torch.no_grad()
def evaluate_accuracy(model, loader, device):
    """
    Evaluates accuracy on a loader (no gradients).
    Returns accuracy in [0,1].
    """
    model.eval()
    correct = 0
    total = 0

    for images, labels in loader:
        images = images.to(device)
        labels = labels.to(device)

        logits = model(images)
        preds = logits.argmax(dim=1)

        correct += (preds == labels).sum().item()
        total += labels.size(0)

    return correct / total


# Train model using function from Task C
for epoch in range(5):
    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)
    test_acc = evaluate_accuracy(model, test_loader, device)
    print(f"Epoch {epoch+1}: loss={train_loss:.4f}, train_acc={train_acc:.4f}, test_acc={test_acc:.4f}")

"""### Task E
What is the testing accuracy that you find?

**Answer:** Using a simple logistic regression model (single linear layer) trained on MNIST for 5 epochs with SGD, the final test accuracy achieved is approximately **92%**.

------------------
## Problem 2 (More Warmup)

A. Build a CNN in Pytorch, and train it on MNIST.

B. What is the testing accuracy you find?

#### CNN on MNIST

Train a CNN digit classifier for strong MNIST performance.
"""

# Define function for CNN
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)   # 28x28 -> 28x28
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28
        self.pool = nn.MaxPool2d(2, 2)                            # 28x28 -> 14x14

        self.fc1 = nn.LazyLinear(128) # automatically infers the input size
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))   # (B,32,14,14)
        x = F.relu(self.conv2(x))              # (B,64,14,14)
        x = x.view(x.size(0), -1)              # flatten
        x = F.relu(self.fc1(x))
        return self.fc2(x)                     # logits

# Train CNN
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = SimpleCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# using a slightly larger test batch size
test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)

for epoch in range(5):
    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)
    test_acc = evaluate_accuracy(model, test_loader, device)
    print(f"Epoch {epoch+1}: loss={train_loss:.4f}, train_acc={train_acc:.4f}, test_acc={test_acc:.4f}")

"""**Testing accuracy:** Using a simple CNN with two convolutional layers and max pooling, trained for 5 epochs on MNIST, the model achieves a test accuracy of approximately **99%**.

This is an improvement over logistic regression and confirms that the CNN has learned robust digit features.

---------------
## Problem 3 (CAPTCHA)

A. Solve the main problem in this notebook.

B. What is the accuracy you find on the clean and noisy **public** captcha problems, for which you have the answer?

C. Submit your answers for the 2500 clean and 2500 noisy **private** captcha problems (for which you do not have the answers).

D. Also submit your notebook with all your documented/commented code.

### Task B
What is the accuracy you find on the clean and noisy public captcha problems, for which you have the answer?
"""

# Load public sets (these have labels)
Xc, yc = readExamples('public-clean')
Xn, yn = readExamples('public-noisy')

# strip newlines/spaces from labels
yc = [s.strip() for s in yc]
yn = [s.strip() for s in yn]

print("public-clean X shape:", Xc.shape, "num labels:", len(yc))
print("public-noisy X shape:", Xn.shape, "num labels:", len(yn))

# check label lengths
lengths = sorted(set(len(s) for s in yc if s))
lengths_n = sorted(set(len(s) for s in yn if s))
print("unique label lengths (clean):", lengths)
print("unique label lengths (noisy):", lengths_n)

# check alphabet (unique characters)
alphabet = sorted(set("".join([s for s in yc if s] + [s for s in yn if s])))
print("alphabet:", alphabet)
print("alphabet size:", len(alphabet))

# verify 5 crops of 28x28 each
chunks = torch.split(Xc[0], 28, dim=-1)
print("num chunks:", len(chunks), "chunk shape:", chunks[0].shape)

"""**Comment:** After training the digit models, we load the captcha data using the readExamples function. Each captcha has shape (1,28, 140), which we interpret as five adjacent 28x28 blocks.

Once we inspect the data and labels, we see each captcha represents an arithmetic expression consisting of two digits, an operator, and two digits. And we must read the digits, infer the operator, compute the arithmetic result and output a number.
"""

Xc, yc = readExamples("public-clean")
x = Xc[0:64]  # make a batch on purpose
chunks = torch.split(x, 28, dim=-1)
d0 = chunks[0]
print("X batch shape:", x.shape)
print("d0 batch shape:", d0.shape)

@torch.no_grad()
def predict_ab_and_opchunk(model, X, device):
    """
    X: (N,1,28,140)
    Returns:
      a: (N,) int tensor in [0,99]
      b: (N,) int tensor in [0,99]
      op_chunk: (N,1,28,28) tensor (the operator image)
    """
    model.eval()
    X = X.to(device)
    c0, c1, c2, c3, c4 = torch.split(X, 28, dim=-1)

    d0 = model(c0).argmax(1)
    d1 = model(c1).argmax(1)
    d3 = model(c3).argmax(1)
    d4 = model(c4).argmax(1)

    a = 10 * d0 + d1
    b = 10 * d3 + d4
    return a.cpu(), b.cpu(), c2.cpu()

# run on a small sample first
Xc, yc = readExamples("public-clean")
yc = [s.strip() for s in yc]

a, b, op = predict_ab_and_opchunk(model, Xc[:10], device)
print("a (first 10):", a.tolist())
print("b (first 10):", b.tolist())
print("true answers (first 10):", yc[:10])
print("operator chunk shape:", op.shape)

"""**Comment:**

At this stage we are only verifying that the captcha image is being split correctly
and that the digit CNN can extract the two two-digit numbers (a and b).
The predicted values of a and b are not expected to match the final labels yet,
because the operator (+ or −) has not been applied.

#### Public-clean
"""

def to_int_list(str_list):
    return torch.tensor([int(s) for s in str_list], dtype=torch.int64)

@torch.no_grad()
def best_threshold_for_plus_minus(model, X, y_str, device):
    """
    Choose an ink threshold t such that:
      predict '+' if ink >= t else '-'
    that maximizes exact-match accuracy on (X, y).
    Returns (best_t, best_acc).
    """
    a, b, op = predict_ab_and_opchunk(model, X, device)
    y = to_int_list([s.strip() for s in y_str])

    ink = op.sum(dim=(1,2,3))  # (N,)

    # candidate thresholds: midpoints of sorted unique ink values
    vals = torch.unique(ink).sort().values
    # if many unique values, we can subsample to keep it fast
    if vals.numel() > 400:
        idx = torch.linspace(0, vals.numel()-1, steps=400).long()
        vals = vals[idx]

    best_t = None
    best_acc = -1.0

    for t in vals:
        pred = torch.where(ink >= t, a + b, a - b)
        acc = (pred == y).float().mean().item()
        if acc > best_acc:
            best_acc = acc
            best_t = float(t.item())

    return best_t, best_acc

# fit threshold on public-clean
Xc, yc = readExamples("public-clean")
yc = [s.strip() for s in yc]

t_star, acc_fit = best_threshold_for_plus_minus(model, Xc, yc, device)
print("best threshold (ink):", t_star)
print("accuracy on public-clean using fitted threshold:", acc_fit)

"""**Comment:**

Here, we infer the operator by measuring the total pixel intensity ("ink")
of the operator chunk. Since '+' typically has more strokes than '−',
its ink value tends to be larger.
We fit an optimal threshold on public-clean data that maximizes
exact-match captcha accuracy, and use this threshold for prediction.

#### Public-noisy
"""

@torch.no_grad()
def accuracy_with_threshold(model, X, y_str, device, t):
    a, b, op = predict_ab_and_opchunk(model, X, device)
    y = to_int_list([s.strip() for s in y_str])
    ink = op.sum(dim=(1,2,3))
    pred = torch.where(ink >= t, a + b, a - b)
    acc = (pred == y).float().mean().item()
    return acc, pred

# public-clean
Xc, yc = readExamples("public-clean")
yc = [s.strip() for s in yc]
acc_clean, pred_clean = accuracy_with_threshold(model, Xc, yc, device, t_star)

# public-noisy
Xn, yn = readExamples("public-noisy")
yn = [s.strip() for s in yn]
acc_noisy, pred_noisy = accuracy_with_threshold(model, Xn, yn, device, t_star)

print("public-clean accuracy:", acc_clean)
print("public-noisy accuracy:", acc_noisy)

# sanity check: show first 10 comparisons on clean
true_clean = [int(s) for s in yc[:10]]
print("clean true (first 10):", true_clean)
print("clean pred (first 10):", pred_clean[:10].tolist())

"""#### Captcha solver improvements

Baseline pipeline and accuracy improvements.

**Comment:**

Using the threshold learned from the public-clean data, we compute full captcha accuracy on both clean and noisy sets. Performance remains high on the **clean data (~95%)**, confirming that digit recognition and operator inference work correctly in the absence of noise. However, accuracy collapses on the **public-noisy (~7%)** set because noise inflates the operator ink values, which breaks the threshold-based operator rule. This indicates that operator inference is the main failure point under noisy conditions.

**Baseline explanation.**

This baseline solution splits each captcha into five chunks and applies the MNIST CNN to the four digit chunks. From these predictions, we reconstruct the two two-digit numbers involved in the arithmetic expression.

To identify the operator, we rely on the public-clean data. For each clean captcha, we compare the true label to both a + b and a - b, which allows us to infer whether the operator is plus or minus. We then average the corresponding operator images to construct plus and minus templates.

For new captcha images, the operator is classified by computing the normalized correlation between the operator chunk and the plus and minus templates.

Given the poor performance on noisy data, we proceed with additional experiments. First, we explore a blur-only denoising approach. Second, we test a more robust method based on retraining the digit CNN using data augmentation, combined with mild Gaussian blur.

#### First experiment: Gausian blur denoiser
In this experiment, we attempt to improve performance on noisy captchas using a preprocessing-only strategy. We keep the original digit CNN trained on clean MNIST unchanged and apply Gaussian blur as a denoising step to the captcha images.

Each captcha is first split into five chunks corresponding to two digits, the operator, and two digits. The digit CNN is applied to the four digit chunks to recover the two two-digit numbers a and b. The operator chunk is classified by comparing it to plus and minus templates using normalized correlation.

When denoising is enabled, Gaussian blur is applied to the full captcha image before chunking, and again to the operator chunk before template matching. The blur removes high-frequency pixel noise and makes the operator shape smoother, which improves template similarity under noisy conditions.
"""

# Gaussian blur denoiser (fixed 5x5 kernel)
def to_int(y):
    return torch.tensor([int(s) for s in y], dtype=torch.int64)

def split5(X):
    return torch.split(X, 28, dim=-1)  # c0,c1,c2,c3,c4

def gaussian_blur_5x5(x):
    k1 = torch.tensor([1.,4.,6.,4.,1.], device=x.device)
    k = (k1[:,None]*k1[None,:]); k = (k/k.sum()).view(1,1,5,5)
    return F.conv2d(x, k, padding=2)

def norm_corr(x, t, eps=1e-6):
    x0 = x - x.mean(dim=(2,3), keepdim=True)
    t0 = t - t.mean(dim=(2,3), keepdim=True)
    xn = x0 / (x0.flatten(1).norm(dim=1).view(-1,1,1,1) + eps)
    tn = t0 / (t0.flatten(1).norm(dim=1).view(1,1,1,1) + eps)
    return (xn * tn).sum(dim=(1,2,3))

@torch.no_grad()
def predict_ab_op(digit_model, X, device):
    digit_model.eval()
    X = X.to(device)
    c0,c1,c2,c3,c4 = split5(X)
    d0 = digit_model(c0).argmax(1); d1 = digit_model(c1).argmax(1)
    d3 = digit_model(c3).argmax(1); d4 = digit_model(c4).argmax(1)
    a = 10*d0 + d1
    b = 10*d3 + d4
    return a.cpu(), b.cpu(), c2.cpu()

@torch.no_grad()
def build_op_templates(digit_model, Xc, yc, device):
    y = to_int(yc)
    a,b,op = predict_ab_op(digit_model, Xc, device)
    plus = (y == (a+b))
    minus = (y == (a-b))
    keep = (plus | minus)
    op = op[keep]; plus = plus[keep]
    return op[plus].mean(0, keepdim=True), op[~plus].mean(0, keepdim=True)

@torch.no_grad()
def solve(digit_model, X, device, plus_t, minus_t, denoise=False):
    Xuse = gaussian_blur_5x5(X.to(device)).cpu() if denoise else X
    a,b,op = predict_ab_op(digit_model, Xuse, device)
    op = op.to(device)
    op_use = gaussian_blur_5x5(op) if denoise else op
    plus = (norm_corr(op_use, plus_t.to(device)) > norm_corr(op_use, minus_t.to(device))).cpu()
    return torch.where(plus, a+b, a-b)

def accuracy(pred, y_str):
    y = to_int([s.strip() for s in y_str])
    return (pred == y).float().mean().item()

plus_t, minus_t = build_op_templates(model, Xc, yc, device)

pred_clean_dn = solve(model, Xc, device, plus_t, minus_t, denoise=True)
pred_noisy_dn = solve(model, Xn, device, plus_t, minus_t, denoise=True)

print("public-clean (denoise):", accuracy(pred_clean_dn, yc))
print("public-noisy (denoise):", accuracy(pred_noisy_dn, yn))

"""**Comment:**

Using this approach, accuracy on **public-noisy** improves substantially compared to the baseline without denoising, reaching approximately **66%**. However, performance on **public-clean decreases slightly to about 92%**, since blurring also removes useful detail from already clean images.

This method shows that simple denoising can partially mitigate noise effects, but it relies entirely on preprocessing and does not address the model's lack of robustness to noise. This motivates the later approach based on retraining the digit CNN with data augmentation next.
"""



"""#### Second experiment: Robust digit model via data augmentation

In this experiment, we improve robustness by modifying the training process of the digit CNN rather than relying only on preprocessing. We retrain the CNN on MNIST using data augmentation that mimics the noise patterns observed in noisy captchas.

During training, we apply Gaussian pixel noise to each MNIST digit, which randomly perturbs pixel intensities while preserving the digit label. We also apply a mild Gaussian blur, encouraging the model to focus on coarse digit structure instead of fine pixel-level details. These augmentations expose the model to a wider range of visual distortions during training.


"""

class AddGaussianNoise:
    def __init__(self, sigma=0.35):
        self.sigma = sigma
    def __call__(self, x):
        return torch.clamp(x + self.sigma * torch.randn_like(x), 0.0, 1.0)

train_tfm_noisy = transforms.Compose([
    transforms.ToTensor(),
    AddGaussianNoise(sigma=0.35),
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.2)),
])

test_tfm = transforms.ToTensor()

train_ds_noisy = torchvision.datasets.MNIST(root="./data", train=True, download=True, transform=train_tfm_noisy)
test_ds_std   = torchvision.datasets.MNIST(root="./data", train=False, download=True, transform=test_tfm)

train_loader_noisy = DataLoader(train_ds_noisy, batch_size=64, shuffle=True)
test_loader_std    = DataLoader(test_ds_std, batch_size=256, shuffle=False)

digit_model_noisy = SimpleCNN().to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(digit_model_noisy.parameters(), lr=1e-3)

for epoch in range(3):
    train_one_epoch(digit_model_noisy, train_loader_noisy, optimizer, criterion, device)
    print("MNIST test acc:", evaluate_accuracy(digit_model_noisy, test_loader_std, device))

"""**Comment:**

The model is evaluated on the standard, clean MNIST test set without any augmentation. Despite being trained on noisy data, the CNN retains high accuracy on clean MNIST, reaching nearly **99%**. This indicates that the augmentations improve robustness without significantly harming performance on clean data.

This retrained digit model is reused in the captcha pipeline:
"""

plus_t2, minus_t2 = build_op_templates(digit_model_noisy, Xc, yc, device)

pred_noisy_no_blur = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=False)
pred_noisy_blur    = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=True)

print("public-noisy no blur:", accuracy(pred_noisy_no_blur, yn))
print("public-noisy with blur:", accuracy(pred_noisy_blur, yn))

"""**Comment:**

Using the digit CNN retrained with noise augmentation, we rebuild the operator templates and evaluate performance on the public noisy set. Even without any denoising, accuracy increases substantially compared to the blur-only baseline **(78%)**, indicating that the digit model itself has learned to be robust to noise. When Gaussian blur is additionally applied at prediction time, accuracy improves slightly further **(79%)**.

This result shows that data augmentation addresses the core robustness issue, while blur acts as a complementary refinement rather than a primary solution.

"""

pred_clean_no_blur = solve(digit_model_noisy, Xc, device, plus_t2, minus_t2, denoise=False)
pred_clean_blur    = solve(digit_model_noisy, Xc, device, plus_t2, minus_t2, denoise=True)

print("public-clean no blur:", accuracy(pred_clean_no_blur, yc))
print("public-clean with blur:", accuracy(pred_clean_blur, yc))

"""**Comment:**

We evaluate the noise-augmented digit model on the public-clean captchas with and without denoising. Accuracy remains high when no blur is applied, confirming that the retrained model preserves strong performance on clean data. Applying Gaussian blur slightly reduces accuracy, as expected, since blurring removes useful detail from already clean images.

Given this result, we will not apply denoising to clean captchas, and apply denoising only to noisy captchas.
"""

def show_noisy_example(idx=0):
    x = Xn[idx:idx+1]
    xb = gaussian_blur_5x5(x.to(device)).cpu()

    a0,b0,_ = predict_ab_op(digit_model_noisy, x, device)
    a1,b1,_ = predict_ab_op(digit_model_noisy, xb, device)

    plt.figure(figsize=(10,3))
    plt.subplot(2,1,1)
    plt.imshow(1 - x[0,0], cmap="gray")
    plt.title(f"Noisy original | a={a0.item()} b={b0.item()}")
    plt.axis("off")

    plt.subplot(2,1,2)
    plt.imshow(1 - xb[0,0], cmap="gray")
    plt.title(f"Noisy blurred | a={a1.item()} b={b1.item()}")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

show_noisy_example(idx=0)

# compute predictions on public-noisy with and without blur
y_true = to_int([s.strip() for s in yn])
pred_nb = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=False)
pred_bl = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=True)

# find an index fixed by blur: wrong before, correct after
fixed = (pred_nb != y_true) & (pred_bl == y_true)

if fixed.any():
    idx = fixed.nonzero()[0].item()
    print("Found example fixed by blur. idx =", idx)
    print("true =", y_true[idx].item(), "no_blur =", pred_nb[idx].item(), "blur =", pred_bl[idx].item())

    x0 = Xn[idx:idx+1]
    x1 = gaussian_blur_5x5(x0.to(device)).cpu()

    # show full captcha before/after
    plt.figure(figsize=(10,3))
    plt.subplot(2,1,1)
    plt.imshow(1 - x0[0,0], cmap="gray")
    plt.title("Noisy original (wrong without blur)")
    plt.axis("off")

    plt.subplot(2,1,2)
    plt.imshow(1 - x1[0,0], cmap="gray")
    plt.title("After blur (correct)")
    plt.axis("off")
    plt.tight_layout()
    plt.show()

    # show chunks before/after
    c0,c1,c2,c3,c4 = split5(x0)
    b0,b1,b2,b3,b4 = split5(x1)

    plt.figure(figsize=(12,4))
    for j, ch in enumerate([c0,c1,c2,c3,c4]):
        plt.subplot(2,5,j+1)
        plt.imshow(1 - ch[0,0], cmap="gray")
        plt.axis("off")
        plt.title(f"orig {j}" if j!=2 else "orig op")

    for j, ch in enumerate([b0,b1,b2,b3,b4]):
        plt.subplot(2,5,5+j+1)
        plt.imshow(1 - ch[0,0], cmap="gray")
        plt.axis("off")
        plt.title(f"blur {j}" if j!=2 else "blur op")

    plt.suptitle("Chunks before vs after blur", y=1.02)
    plt.tight_layout()
    plt.show()

else:
    print("No examples found where blur fixes an error (unexpected).")

# Compare correctness with and without blur on public-noisy
y_true = to_int([s.strip() for s in yn])

pred_nb = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=False)
pred_bl = solve(digit_model_noisy, Xn, device, plus_t2, minus_t2, denoise=True)

correct_nb = (pred_nb == y_true)
correct_bl = (pred_bl == y_true)

print("Total samples:", len(y_true))
print("Correct without blur:", correct_nb.sum().item())
print("Correct with blur:", correct_bl.sum().item())

print("Fixed by blur (wrong → correct):", ((~correct_nb) & correct_bl).sum().item())
print("Broken by blur (correct → wrong):", (correct_nb & (~correct_bl)).sum().item())
print("Correct in both:", (correct_nb & correct_bl).sum().item())
print("Wrong in both:", ((~correct_nb) & (~correct_bl)).sum().item())

"""**Comment:**

To further confirm our prediction approach, here we can see that applying Gaussian blur to noisy captchas leads to a net improvement in accuracy. Out of 2500 samples, blur fixes 191 previously incorrect predictions, while breaking 165 predictions that were previously correct. This results in an overall gain of 26 correct predictions. Although blur does not help every case, the net effect is positive, which justifies using blur for noisy captchas in the final pipeline.

Based on this analysis, we will apply blur when predicting noisy captchas and do not apply blur for clean captchas.

### Task C
Submit your answers for the 2500 clean and 2500 noisy private captcha problems (for which you do not have the answers).
"""

# load private sets w/o labels
Xp_c, _ = readExamples("private-clean")
Xp_n, _ = readExamples("private-noisy")

print(Xp_c.shape, Xp_n.shape)

# Build operator templates using public-clean (labeled) and the robust digit model
plus_t2, minus_t2 = build_op_templates(digit_model_noisy, Xc, yc, device)

# Predict private-clean without blur, private-noisy with blur
pred_private_clean = solve(digit_model_noisy, Xp_c, device, plus_t2, minus_t2, denoise=False)
pred_private_noisy = solve(digit_model_noisy, Xp_n, device, plus_t2, minus_t2, denoise=True)

# Write to txt files (one integer per line)
with open("private-clean.txt", "w") as f:
    for v in pred_private_clean.tolist():
        f.write(f"{int(v)}\n")

with open("private-noisy.txt", "w") as f:
    for v in pred_private_noisy.tolist():
        f.write(f"{int(v)}\n")

# write results to text files with one numerical answer per line
from google.colab import files
files.download("private-clean.txt")
files.download("private-noisy.txt")